# LeetCode 315: Count of Smaller Numbers After Self

## Problem Statement

Given an integer array `nums`, return an integer array `counts` where `counts[i]` is the number of smaller elements to the right of `nums[i]`.

## Approaches

### 1. Brute Force Approach

- **Idea:**  
  For each element in the array, iterate over all the elements to its right and count how many are smaller.
- **Time Complexity:**  
  O(n²) – Each element is compared with all elements to its right.
- **Space Complexity:**  
  O(1) (excluding the output array)
- **Discussion:**  
  Although easy to implement, this approach is inefficient for large inputs due to its quadratic time complexity.

### 2. Merge Sort Approach

- **Idea:**  
  Modify the classic merge sort algorithm to count the number of smaller elements during the merge process.  
  Instead of sorting the actual values directly, maintain an array of indices corresponding to the original positions of the elements. During the merge step, when an element from the right subarray is merged before an element from the left subarray, increment the count for that left element.
- **Time Complexity:**  
  O(n log n) – Due to the recursive divide and merge steps of merge sort.
- **Space Complexity:**  
  O(n) – Extra space is needed for auxiliary arrays and to maintain indices.
- **Discussion:**  
  This approach significantly reduces time complexity by leveraging the divide and conquer paradigm. It is a common method in interviews to demonstrate an understanding of efficient algorithms and inversion counting.

### 3. Fenwick Tree (Binary Indexed Tree) Approach

- **Idea:**  
  Use a Fenwick Tree to efficiently manage cumulative frequencies.
  1. **Coordinate Compression:** Map each unique number in the array to a continuous range (rank) since the input values can be large or negative.
  2. **Processing:** Traverse the array from right to left. For each element, use the Fenwick Tree to query how many numbers with a smaller rank have already been processed. This gives the count of smaller elements to the right.
  3. **Updating:** After querying, update the tree by increasing the count for the current element’s rank.
- **Time Complexity:**  
  O(n log n) – Each update and query operation on the Fenwick Tree takes O(log n), and these are performed for each element.
- **Space Complexity:**  
  O(n) – Extra space is used for the Fenwick Tree structure and the coordinate compression mapping.
- **Discussion:**  
  The Fenwick Tree method is an alternative efficient solution that showcases familiarity with advanced data structures. It is particularly useful when there are frequent dynamic updates and queries.

## Complexity Analysis Summary

- **Merge Sort Approach:**
  - _Time Complexity:_ O(n log n)
  - _Space Complexity:_ O(n)
- **Fenwick Tree Approach:**
  - _Time Complexity:_ O(n log n)
  - _Space Complexity:_ O(n)

## Interview Discussion

In a coding interview, I would start by outlining the brute force approach to demonstrate a clear understanding of the problem, then explain its inefficiency due to an O(n²) time complexity. I would proceed to describe the merge sort based solution, explaining how the divide and conquer paradigm is used to efficiently count smaller elements during merging, achieving an O(n log n) time complexity with O(n) space. Finally, I would present the Fenwick Tree approach, emphasizing the use of coordinate compression and cumulative frequency queries, which also runs in O(n log n) time and O(n) space. This comprehensive discussion not only shows multiple methods to solve the problem but also demonstrates knowledge of both algorithm optimization and advanced data structures.

_Both the merge sort and Fenwick Tree approaches are highly optimized for this problem, and the choice between them often comes down to personal preference or specific use-case requirements._
